"""
å¢å¼ºç‰ˆè®­ç»ƒè„šæœ¬ - é€‚ç”¨äºæœ¬åœ°å’ŒColabé•¿æ—¶é—´è®­ç»ƒ
è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
"""

from transformers import (
    GPT2Tokenizer, GPT2LMHeadModel,
    TextDataset, DataCollatorForLanguageModeling,
    Trainer, TrainingArguments, TrainerCallback
    )
import os
import sys
import json
import math
import time
import torch
import signal
import logging
import subprocess
import importlib
import platform
from datetime import datetime
from pathlib import Path
import matplotlib.pyplot as plt
from tqdm import tqdm
import random

# ========== ç¯å¢ƒæ£€æµ‹å’Œä¾èµ–å®‰è£… ==========


def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…"""

    # éœ€è¦å®‰è£…çš„åŒ…åˆ—è¡¨
    required_packages = [
        'transformers[torch]>=4.30.0',
        'datasets>=2.14.0',
        'accelerate>=0.21.0',
        'matplotlib>=3.7.0',
        'tqdm>=4.65.0',
        ]

    # å¯é€‰åŒ…åˆ—è¡¨ï¼ˆä»…ç”¨äºæœ¬åœ°ç¯å¢ƒï¼‰
    optional_packages = [
        'torch>=2.0.0',
        'torchvision>=0.15.0',
        ]

    print("=" * 60)
    print("æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…")
    print("=" * 60)

    # æ£€æŸ¥å½“å‰Pythonç‰ˆæœ¬
    python_version = platform.python_version()
    print(f"Pythonç‰ˆæœ¬: {python_version}")

    # æ£€æŸ¥pipæ˜¯å¦å¯ç”¨
    try:
        import pip
        print("âœ“ pipå·²å®‰è£…")
    except ImportError:
        print("âŒ pipæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…pip")
        sys.exit(1)

    # æ£€æŸ¥torchæ˜¯å¦å·²å®‰è£…ï¼ˆå¦‚æœæœªå®‰è£…ï¼Œéœ€è¦æ ¹æ®ç³»ç»Ÿå®‰è£…åˆé€‚çš„ç‰ˆæœ¬ï¼‰
    try:
        import torch
        print(f"âœ“ PyTorchå·²å®‰è£…: {torch.__version__}")
    except ImportError:
        print("âš  PyTorchæœªå®‰è£…ï¼Œå°†è‡ªåŠ¨å®‰è£…...")
        # æ ¹æ®ç³»ç»Ÿå’ŒCUDAç‰ˆæœ¬é€‰æ‹©åˆé€‚çš„torchç‰ˆæœ¬
        system = platform.system()

        # æ£€æŸ¥æ˜¯å¦æœ‰CUDA
        cuda_available = False
        try:
            import subprocess
            result = subprocess.run(
                ['nvidia-smi'], capture_output=True, text=True)
            cuda_available = result.returncode == 0
        except BaseException:
            pass

        if cuda_available and system == "Linux":
            torch_package = "torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
        elif cuda_available and system == "Windows":
            torch_package = "torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
        else:
            torch_package = "torch torchvision torchaudio"

        required_packages = [torch_package] + required_packages

    # å®‰è£…æ‰€æœ‰å¿…éœ€çš„åŒ…
    print("\nå®‰è£…å¿…éœ€çš„åŒ…:")
    for package in required_packages:
        print(f"æ­£åœ¨å®‰è£…: {package}")
        try:
            # ä½¿ç”¨subprocesså®‰è£…åŒ…
            subprocess.check_call(
                [sys.executable, "-m", "pip", "install", package, "--quiet"])
            print(f"  âœ“ {package.split()[0] if ' ' in package else package}")
        except subprocess.CalledProcessError as e:
            print(f"  âŒ å®‰è£…å¤±è´¥: {package}")
            print(f"    é”™è¯¯: {e}")

    # å¯é€‰å®‰è£…çš„åŒ…ï¼ˆä¸å¼ºåˆ¶ï¼‰
    print("\nå¯é€‰å®‰è£…çš„åŒ…:")
    for package in optional_packages:
        try:
            # å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™å®‰è£…
            importlib.import_module(package.split('>=')[0].split('[')[0])
            print(f"  âœ“ {package} (å·²å®‰è£…)")
        except ImportError:
            print(f"  å¯é€‰: {package} (æœªå®‰è£…ï¼Œè·³è¿‡)")

    print("\nâœ“ ä¾èµ–æ£€æŸ¥å®Œæˆ")
    print("=" * 60)


# ========== Colabç¯å¢ƒæ£€æµ‹ ==========
IS_COLAB = 'COLAB_GPU' in os.environ

# å¦‚æœæ˜¯Colabç¯å¢ƒï¼Œå®‰è£…å¿…è¦çš„åŒ…
if IS_COLAB:
    print(f"è¿è¡Œç¯å¢ƒ: Google Colab")

    # åœ¨Colabä¸­å®‰è£…å¿…è¦çš„åŒ…
    try:
        import subprocess
        subprocess.check_call([
            sys.executable, "-m", "pip", "install",
            "transformers[torch]", "datasets", "accelerate", "matplotlib", "tqdm", "--quiet"
            ])
        print("âœ“ Colabç¯å¢ƒä¾èµ–å®‰è£…å®Œæˆ")
    except Exception as e:
        print(f"âŒ Colabä¾èµ–å®‰è£…å¤±è´¥: {e}")

    # è‡ªåŠ¨æŒ‚è½½Google Drive
    from google.colab import drive
    drive_mounted = False
    try:
        drive.mount('/content/drive', force_remount=True)
        drive_mounted = True
        print("âœ“ Google Drive æŒ‚è½½æˆåŠŸ")
    except Exception as e:
        print(f"DriveæŒ‚è½½å¤±è´¥: {e}")
        print("å°†ä½¿ç”¨Colabä¸´æ—¶å­˜å‚¨")
else:
    print(f"è¿è¡Œç¯å¢ƒ: æœ¬åœ°ç¯å¢ƒ ({platform.system()})")

    # åœ¨æœ¬åœ°ç¯å¢ƒä¸­æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
    check_and_install_dependencies()

# ========== å¯¼å…¥Transformersåº“ï¼ˆåœ¨å®‰è£…åï¼‰ ==========

# ========== é…ç½®éƒ¨åˆ† ==========


class TrainingConfig:
    """è®­ç»ƒé…ç½®ç±» - åªä¿ç•™ç´§æ€¥å­˜æ¡£ï¼Œæ‰€æœ‰æ–‡ä»¶å­˜å‚¨äºGoogle Driveæˆ–æœ¬åœ°"""

    # åŸºç¡€è·¯å¾„é…ç½®
    if IS_COLAB:
        # Colabç¯å¢ƒä½¿ç”¨Google Drive
        BASE_DIR = "/content/drive/MyDrive/LLM_Impossible_Training"
    else:
        # æœ¬åœ°ç¯å¢ƒ - ä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹
        home_dir = os.path.expanduser("~")
        BASE_DIR = os.path.join(home_dir, "LLM_Impossible_Training")

    # æ•°æ®è·¯å¾„
    DATA_DIR = os.path.join(BASE_DIR, "data")

    # ç»“æœä¿å­˜è·¯å¾„
    RESULTS_DIR = os.path.join(BASE_DIR, "results")

    # ç´§æ€¥å­˜æ¡£ä¿å­˜è·¯å¾„
    EMERGENCY_DIR = os.path.join(BASE_DIR, "emergency_backups")

    # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    LOG_FILE = os.path.join(BASE_DIR, "training.log")

    # è®­ç»ƒé…ç½®
    BATCH_SIZE = 4
    NUM_EPOCHS = 5
    LEARNING_RATE = 5e-5
    SAVE_STEPS = 1000  # è®¾ç½®ä¸ºå¤§å€¼ï¼Œç¦ç”¨å¸¸è§„ä¿å­˜
    LOGGING_STEPS = 5
    MAX_CHECKPOINTS = 0  # ä¸ä¿ç•™å¸¸è§„æ£€æŸ¥ç‚¹

    # æ•°æ®é›†é…ç½®
    DATASETS = [
        {
            "name": "Natural Language",
            "file_path": os.path.join(DATA_DIR, "data_natural.txt"),
            "model_dir": os.path.join(RESULTS_DIR, "model_natural"),
            "emergency_dir": os.path.join(EMERGENCY_DIR, "natural_language"),
            "storage_location": "drive" if IS_COLAB else "local",
            "resume_checkpoint": None
            },
        {
            "name": "Impossible Language (Reversed)",
            "file_path": os.path.join(DATA_DIR, "impossible_output_reversed.txt"),
            "model_dir": os.path.join(RESULTS_DIR, "model_reversed"),
            "emergency_dir": os.path.join(EMERGENCY_DIR, "reversed"),
            "storage_location": "drive" if IS_COLAB else "local",
            "resume_checkpoint": None
            },
        {
            "name": "Impossible Language (Parity Negation)",
            "file_path": os.path.join(DATA_DIR, "impossible_output_parity_negation.txt"),
            "model_dir": os.path.join(RESULTS_DIR, "model_parity_negation"),
            "emergency_dir": os.path.join(EMERGENCY_DIR, "parity_negation"),
            "storage_location": "drive" if IS_COLAB else "local",
            "resume_checkpoint": None
            }
        ]

    @classmethod
    def create_directories(cls):
        """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•"""
        # ä¸»ç›®å½•
        directories = [
            cls.BASE_DIR,
            cls.DATA_DIR,
            cls.RESULTS_DIR,
            cls.EMERGENCY_DIR
            ]

        print("åˆ›å»ºç›®å½•ç»“æ„:")
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"  âœ“ {directory}")

        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºå…·ä½“ç›®å½•
        print("\nåˆ›å»ºæ•°æ®é›†ç›®å½•:")
        for dataset in cls.DATASETS:
            os.makedirs(dataset["model_dir"], exist_ok=True)
            os.makedirs(dataset["emergency_dir"], exist_ok=True)
            print(f"  âœ“ {dataset['name']}: {dataset['model_dir']}")

# ========== ä¿æŒæ´»è·ƒç®¡ç†å™¨ ==========


class KeepAliveManager:
    @staticmethod
    def simulate_activity():
        """æ¨¡æ‹Ÿç”¨æˆ·æ´»åŠ¨ï¼Œé˜²æ­¢Colabæ–­å¼€è¿æ¥"""
        try:
            print(f"[ä¿æŒæ´»è·ƒ] {datetime.now().strftime('%H:%M:%S')} - è®­ç»ƒä»åœ¨è¿›è¡Œä¸­...")

            # è½»å¾®çš„å†…å­˜æ“ä½œ
            dummy_var = [random.random() for _ in range(1000)]
            del dummy_var

            # æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.memory_allocated() / 1024**3
                print(f"[GPUå†…å­˜] å·²ä½¿ç”¨: {gpu_memory:.2f} GB")
            else:
                print("[å†…å­˜] ä½¿ç”¨CPUè®­ç»ƒ")

            return True
        except Exception as e:
            print(f"[ä¿æŒæ´»è·ƒ] é”™è¯¯: {e}")
            return False

# ========== æ—¥å¿—é…ç½® ==========


def setup_logging(log_file):
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    # ç¡®ä¿æ—¥å¿—æ–‡ä»¶æ‰€åœ¨ç›®å½•å­˜åœ¨
    log_dir = os.path.dirname(log_file)
    if log_dir and not os.path.exists(log_dir):
        os.makedirs(log_dir, exist_ok=True)

    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # ç§»é™¤ç°æœ‰çš„å¤„ç†å™¨ï¼Œé¿å…é‡å¤
    if logger.handlers:
        logger.handlers.clear()

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    # æ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    # æ·»åŠ å¤„ç†å™¨
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger

# ========== è‡ªå®šä¹‰å›è°ƒå‡½æ•° - åªä¿ç•™ç´§æ€¥å­˜æ¡£ ==========


class EmergencyOnlyCallback(TrainerCallback):
    """åªä¿ç•™ç´§æ€¥å­˜æ¡£çš„å›è°ƒå‡½æ•°"""

    def __init__(self, trainer, emergency_dir, model_dir, logger=None):
        self.trainer = trainer
        self.emergency_dir = emergency_dir
        self.model_dir = model_dir
        self.logger = logger
        self.perplexities = []  # åªè®°å½•å›°æƒ‘åº¦
        self.start_time = time.time()
        self.last_emergency_time = time.time()
        self.last_keepalive_time = time.time()
        self.emergency_save_interval = 300  # æ¯5åˆ†é’Ÿç´§æ€¥ä¿å­˜ä¸€æ¬¡

        logger.info(f"åˆå§‹åŒ–ç´§æ€¥å­˜æ¡£å›è°ƒï¼Œç´§æ€¥å­˜æ¡£ç›®å½•: {emergency_dir}")
        logger.info("å·²ç¦ç”¨æ‰€æœ‰å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™ç´§æ€¥å­˜æ¡£")

    def on_log(self, args, state, control, logs=None, **kwargs):
        """è®°å½•æ—¥å¿—æ—¶è§¦å‘ - åªè®¡ç®—å’Œè®°å½•å›°æƒ‘åº¦"""
        if logs and 'loss' in logs:
            # è®¡ç®—å›°æƒ‘åº¦
            loss = logs['loss']
            perplexity = math.exp(loss) if loss < 100 else float('inf')

            # åªæ·»åŠ å›°æƒ‘åº¦åˆ°æ—¥å¿—
            logs['perplexity'] = perplexity
            self.perplexities.append(perplexity)

            # æ—¥å¿—åªæ˜¾ç¤ºå›°æƒ‘åº¦
            if self.logger:
                self.logger.info(
                    f"æ­¥æ•° {state.global_step}: å›°æƒ‘åº¦ = {perplexity:.4f}")

            # å®šæœŸæ¨¡æ‹Ÿæ´»åŠ¨ï¼Œé˜²æ­¢æ–­å¼€ï¼ˆä»…Colabï¼‰
            current_time = time.time()
            if IS_COLAB and current_time - self.last_keepalive_time > 300:  # æ¯5åˆ†é’Ÿ
                KeepAliveManager.simulate_activity()
                self.last_keepalive_time = current_time

            # å®šæœŸç´§æ€¥ä¿å­˜ï¼ˆæ¯5åˆ†é’Ÿï¼‰
            if current_time - self.last_emergency_time > self.emergency_save_interval:
                self._emergency_save(state)
                self.last_emergency_time = current_time

    def on_step_end(self, args, state, control, **kwargs):
        """æ¯ä¸ªè®­ç»ƒæ­¥ç»“æŸæ—¶è§¦å‘"""
        # æ¯100æ­¥ç´§æ€¥ä¿å­˜ä¸€æ¬¡ï¼ˆé¢å¤–ä¿æŠ¤ï¼‰
        if state.global_step % 100 == 0:
            self._emergency_save(state)

    def on_epoch_end(self, args, state, control, **kwargs):
        """æ¯ä¸ªepochç»“æŸæ—¶è§¦å‘"""
        if self.logger:
            self.logger.info(
                f"Epoch {state.epoch} å®Œæˆï¼Œæ€»æ­¥æ•°: {state.global_step}")
        # ä¸ä¿å­˜å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œåªè®°å½•æ—¥å¿—

    def on_train_end(self, args, state, control, **kwargs):
        """è®­ç»ƒç»“æŸæ—¶è§¦å‘"""
        if self.logger:
            self.logger.info("è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹...")
        self._save_final_model(state)

    def _emergency_save(self, state):
        """ç´§æ€¥å­˜æ¡£ - åªä¿ç•™è¿™ä¸€ä¸ªå­˜æ¡£åŠŸèƒ½"""
        try:
            # åˆ›å»ºç´§æ€¥å­˜æ¡£ç›®å½•
            timestamp = int(time.time())
            save_dir = os.path.join(
                self.emergency_dir,
                f"emergency_{timestamp}")
            os.makedirs(save_dir, exist_ok=True)

            # ä¿å­˜çŠ¶æ€ä¿¡æ¯
            state_info = {
                "global_step": state.global_step,
                "epoch": state.epoch,
                "save_time": datetime.now().isoformat(),
                "perplexities": self.perplexities[-100:] if self.perplexities else [],
                "total_training_time": time.time() - self.start_time
                }

            with open(os.path.join(save_dir, "emergency_state.json"), 'w') as f:
                json.dump(state_info, f, indent=2)

            # ä¿å­˜æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
            try:
                self.trainer.model.save_pretrained(save_dir)
                if self.trainer.tokenizer is not None:
                    self.trainer.tokenizer.save_pretrained(save_dir)
            except Exception as e:
                self.logger.warning(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")

            # æ¸…ç†æ—§çš„ç´§æ€¥å­˜æ¡£ï¼ˆåªä¿ç•™æœ€æ–°çš„3ä¸ªï¼‰
            self._cleanup_old_emergency_backups()

            if self.logger:
                self.logger.info(f"ç´§æ€¥å­˜æ¡£ä¿å­˜åˆ°: {save_dir}")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ç´§æ€¥å­˜æ¡£å¤±è´¥: {e}")

    def _cleanup_old_emergency_backups(self):
        """æ¸…ç†æ—§çš„ç´§æ€¥å­˜æ¡£ï¼Œåªä¿ç•™æœ€æ–°çš„3ä¸ª"""
        try:
            if not os.path.exists(self.emergency_dir):
                return

            # è·å–æ‰€æœ‰ç´§æ€¥å­˜æ¡£ç›®å½•
            emergency_dirs = []
            for item in os.listdir(self.emergency_dir):
                if item.startswith("emergency_"):
                    item_path = os.path.join(self.emergency_dir, item)
                    if os.path.isdir(item_path):
                        emergency_dirs.append(
                            (item_path, os.path.getmtime(item_path)))

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            emergency_dirs.sort(key=lambda x: x[1], reverse=True)

            # åˆ é™¤æ—§çš„å­˜æ¡£ï¼Œåªä¿ç•™æœ€æ–°çš„3ä¸ª
            for i in range(3, len(emergency_dirs)):
                import shutil
                shutil.rmtree(emergency_dirs[i][0])
                self.logger.info(f"æ¸…ç†æ—§ç´§æ€¥å­˜æ¡£: {emergency_dirs[i][0]}")

        except Exception as e:
            self.logger.error(f"æ¸…ç†ç´§æ€¥å­˜æ¡£å¤±è´¥: {e}")

    def _save_final_model(self, state):
        """ä¿å­˜æœ€ç»ˆæ¨¡å‹"""
        try:
            # æœ€ç»ˆæ¨¡å‹è·¯å¾„
            final_model_path = os.path.join(self.model_dir, "final_model")

            # æ¸…ç©ºç›®å½•ï¼Œåªä¿ç•™æœ€ç»ˆæ¨¡å‹
            if os.path.exists(final_model_path):
                import shutil
                shutil.rmtree(final_model_path)

            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            self.trainer.model.save_pretrained(final_model_path)
            if self.trainer.tokenizer is not None:
                self.trainer.tokenizer.save_pretrained(final_model_path)

            # ä¿å­˜å›°æƒ‘åº¦ç»“æœ
            perplexity_result = {
                "perplexities": self.perplexities,
                "final_perplexity": self.perplexities[-1] if self.perplexities else None,
                "min_perplexity": min(self.perplexities) if self.perplexities else None,
                "global_step": state.global_step,
                "epoch": state.epoch,
                "save_time": datetime.now().isoformat(),
                "total_training_time": time.time() - self.start_time
                }

            with open(os.path.join(final_model_path, "perplexity_results.json"), 'w') as f:
                json.dump(perplexity_result, f, indent=2)

            self.logger.info(f"æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {final_model_path}")

            # æ¸…ç†ç´§æ€¥å­˜æ¡£ç›®å½•ï¼ˆè®­ç»ƒå®Œæˆï¼‰
            if os.path.exists(self.emergency_dir):
                import shutil
                shutil.rmtree(self.emergency_dir)
                self.logger.info(f"è®­ç»ƒå®Œæˆï¼Œæ¸…ç†ç´§æ€¥å­˜æ¡£ç›®å½•: {self.emergency_dir}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜æœ€ç»ˆæ¨¡å‹å¤±è´¥: {e}")

# ========== è®­ç»ƒå‡½æ•° - åªä¿ç•™ç´§æ€¥å­˜æ¡£ ==========


def train_with_emergency_only(
        config, dataset_config, model_name, tokenizer, logger):
    """åªä¿ç•™ç´§æ€¥å­˜æ¡£çš„è®­ç»ƒå‡½æ•°"""

    logger.info(f"å¼€å§‹è®­ç»ƒ: {model_name}")
    logger.info(f"æ•°æ®æ–‡ä»¶: {dataset_config['file_path']}")
    logger.info(f"æœ€ç»ˆæ¨¡å‹å°†ä¿å­˜åˆ°: {dataset_config['model_dir']}")
    logger.info(f"ç´§æ€¥å­˜æ¡£å°†ä¿å­˜åˆ°: {dataset_config['emergency_dir']}")
    logger.info("æ³¨æ„: å·²ç¦ç”¨å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™ç´§æ€¥å­˜æ¡£")

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_config['file_path']):
        logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_config['file_path']}")
        logger.info("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å·²æ”¾ç½®åœ¨æ­£ç¡®ä½ç½®")
        logger.info(f"æ•°æ®æ–‡ä»¶åº”è¯¥ä½äº: {dataset_config['file_path']}")
        return None, None

    # åˆ›å»ºæ¨¡å‹è¾“å‡ºç›®å½•
    model_dir = dataset_config['model_dir']
    os.makedirs(model_dir, exist_ok=True)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(model_dir, "final_model")
    if os.path.exists(final_model_path):
        logger.info(f"å‘ç°å·²æœ‰æœ€ç»ˆæ¨¡å‹: {final_model_path}")
        if IS_COLAB:
            # åœ¨Colabä¸­è¯¢é—®ç”¨æˆ·
            choice = input(f"æ¨¡å‹ '{model_name}' å·²è®­ç»ƒå®Œæˆï¼Œæ˜¯å¦é‡æ–°è®­ç»ƒï¼Ÿ(y/N): ")
            if choice.lower() != 'y':
                logger.info(f"è·³è¿‡æ¨¡å‹: {model_name}")

                # åŠ è½½å·²æœ‰çš„å›°æƒ‘åº¦ç»“æœ
                try:
                    result_file = os.path.join(
                        final_model_path, "perplexity_results.json")
                    with open(result_file, 'r') as f:
                        existing_results = json.load(f)
                    return [], existing_results.get("perplexities", [])
                except BaseException:
                    return [], []
        else:
            # åœ¨æœ¬åœ°ç¯å¢ƒä¸­ï¼Œé»˜è®¤ä¸é‡æ–°è®­ç»ƒ
            logger.info(f"è·³è¿‡å·²è®­ç»ƒçš„æ¨¡å‹: {model_name}")
            try:
                result_file = os.path.join(
                    final_model_path, "perplexity_results.json")
                with open(result_file, 'r') as f:
                    existing_results = json.load(f)
                return [], existing_results.get("perplexities", [])
            except BaseException:
                return [], []

    # æ£€æŸ¥æ˜¯å¦æœ‰å¯æ¢å¤çš„ç´§æ€¥å­˜æ¡£
    resume_from_checkpoint = None
    emergency_dir = dataset_config['emergency_dir']

    if os.path.exists(emergency_dir):
        # æŸ¥æ‰¾æœ€æ–°çš„ç´§æ€¥å­˜æ¡£
        emergency_dirs = []
        for item in os.listdir(emergency_dir):
            if item.startswith("emergency_"):
                item_path = os.path.join(emergency_dir, item)
                if os.path.isdir(item_path):
                    emergency_dirs.append(
                        (item_path, os.path.getmtime(item_path)))

        if emergency_dirs:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„ç´§æ€¥å­˜æ¡£
            emergency_dirs.sort(key=lambda x: x[1], reverse=True)
            latest_emergency = emergency_dirs[0][0]
            resume_from_checkpoint = latest_emergency
            logger.info(f"å‘ç°ç´§æ€¥å­˜æ¡£: {resume_from_checkpoint}")

            # åŠ è½½è®­ç»ƒçŠ¶æ€
            state_file = os.path.join(latest_emergency, "emergency_state.json")
            if os.path.exists(state_file):
                with open(state_file, 'r') as f:
                    state_info = json.load(f)
                logger.info(
                    f"æ¢å¤è®­ç»ƒçŠ¶æ€: æ­¥æ•°={state_info.get('global_step', 0)}, epoch={state_info.get('epoch', 0)}")

    # åŠ è½½æ¨¡å‹
    try:
        if resume_from_checkpoint and os.path.exists(resume_from_checkpoint):
            model = GPT2LMHeadModel.from_pretrained(resume_from_checkpoint)
            logger.info(f"ä»ç´§æ€¥å­˜æ¡£æ¢å¤è®­ç»ƒ: {resume_from_checkpoint}")
        else:
            model = GPT2LMHeadModel.from_pretrained("gpt2")
            logger.info("åˆ›å»ºæ–°çš„GPT-2æ¨¡å‹")
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}ï¼Œåˆ›å»ºæ–°æ¨¡å‹")
        model = GPT2LMHeadModel.from_pretrained("gpt2")

    # å‡†å¤‡æ•°æ®é›†
    try:
        train_dataset = TextDataset(
            tokenizer=tokenizer,
            file_path=dataset_config['file_path'],
            block_size=128
            )
        logger.info(f"æ•°æ®é›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(train_dataset)}")
    except Exception as e:
        logger.error(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        return None, None

    # æ•°æ®æ”¶é›†å™¨
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=False
        )

    # è®­ç»ƒå‚æ•° - ç¦ç”¨æ‰€æœ‰å¸¸è§„æ£€æŸ¥ç‚¹
    training_args = TrainingArguments(
        output_dir=dataset_config['emergency_dir'],  # è¾“å‡ºç›®å½•è®¾ç½®ä¸ºç´§æ€¥å­˜æ¡£ç›®å½•
        overwrite_output_dir=False,  # ä¸è¦†ç›–ï¼Œä¿ç•™ç´§æ€¥å­˜æ¡£
        num_train_epochs=config.NUM_EPOCHS,
        per_device_train_batch_size=config.BATCH_SIZE,
        logging_steps=config.LOGGING_STEPS,
        save_steps=config.SAVE_STEPS,  # è®¾ç½®ä¸ºå¤§å€¼ï¼Œç¦ç”¨å¸¸è§„ä¿å­˜
        save_total_limit=config.MAX_CHECKPOINTS,  # è®¾ç½®ä¸º0ï¼Œä¸ä¿ç•™å¸¸è§„æ£€æŸ¥ç‚¹
        learning_rate=config.LEARNING_RATE,
        weight_decay=0.01,
        adam_epsilon=1e-8,
        max_grad_norm=1.0,
        max_steps=700,
        warmup_steps=100,
        save_strategy="no",  # ç¦ç”¨ä¿å­˜ç­–ç•¥
        load_best_model_at_end=False,
        report_to="none",
        push_to_hub=False,
        remove_unused_columns=False,
        gradient_accumulation_steps=1,
        dataloader_num_workers=0,
        disable_tqdm=False,
        logging_first_step=True,
        logging_dir=os.path.join(model_dir, "logs"),
        eval_strategy="no",
        save_safetensors=False,
        save_on_each_node=False,
        no_cuda=not torch.cuda.is_available(),
        )

    # åˆ›å»ºç´§æ€¥å­˜æ¡£ç›®å½•
    emergency_dir = dataset_config['emergency_dir']
    os.makedirs(emergency_dir, exist_ok=True)

    # åˆ›å»ºTrainer
    trainer = Trainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        train_dataset=train_dataset,
        tokenizer=tokenizer,
        )

    # æ·»åŠ åªä¿ç•™ç´§æ€¥å­˜æ¡£çš„å›è°ƒ
    emergency_callback = EmergencyOnlyCallback(
        trainer, emergency_dir, model_dir, logger=logger)
    trainer.add_callback(emergency_callback)

    # å¼€å§‹è®­ç»ƒ
    try:
        logger.info("å¼€å§‹è®­ç»ƒè¿‡ç¨‹...")
        logger.info("=" * 60)
        logger.info("è®­ç»ƒé…ç½®ï¼š")
        logger.info(f"1. æœ€ç»ˆæ¨¡å‹å°†ä¿å­˜åˆ°: {model_dir}")
        logger.info(f"2. ç´§æ€¥å­˜æ¡£å°†ä¿å­˜åˆ°: {emergency_dir}")
        logger.info(f"3. å·²ç¦ç”¨æ‰€æœ‰å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™ç´§æ€¥å­˜æ¡£")
        logger.info(f"4. ç´§æ€¥å­˜æ¡£æ¯5åˆ†é’Ÿè‡ªåŠ¨ä¿å­˜ä¸€æ¬¡")
        logger.info(f"5. å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥ä»æœ€æ–°ç´§æ€¥å­˜æ¡£æ¢å¤")
        logger.info("=" * 60)

        train_result = trainer.train(
            resume_from_checkpoint=resume_from_checkpoint)

        # æ”¶é›†è®­ç»ƒæŒ‡æ ‡
        perplexities = emergency_callback.perplexities

        logger.info(f"è®­ç»ƒå®Œæˆ: {model_name}")
        if perplexities:
            logger.info(f"æœ€ç»ˆå›°æƒ‘åº¦: {perplexities[-1]:.4f}")
            logger.info(f"æœ€å°å›°æƒ‘åº¦: {min(perplexities):.4f}")
            logger.info(
                f"å›°æƒ‘åº¦ä¸‹é™: {(perplexities[0] - perplexities[-1]):.4f}" if len(perplexities) > 1 else "N/A")

        return perplexities, train_result

    except KeyboardInterrupt:
        logger.warning(f"è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­: {model_name}")
        # ç´§æ€¥ä¿å­˜
        emergency_callback._emergency_save(trainer.state)
        return None, None

    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())

        # å°è¯•ç´§æ€¥ä¿å­˜
        try:
            emergency_callback._emergency_save(trainer.state)
        except BaseException:
            pass

        return None, None

# ========== ä¸»å‡½æ•° ==========


def main():
    """ä¸»è®­ç»ƒå‡½æ•° - åªä¿ç•™ç´§æ€¥å­˜æ¡£"""

    print("=" * 80)
    print("è®­ç»ƒè„šæœ¬ - ä¸å¯èƒ½è¯­è¨€å®éªŒ")
    print(f"è¿è¡Œç¯å¢ƒ: {'Google Colab' if IS_COLAB else 'æœ¬åœ°ç¯å¢ƒ'}")
    print("åªä¿ç•™ç´§æ€¥å­˜æ¡£")
    print("=" * 80)

    # ç¯å¢ƒä¿¡æ¯
    if not IS_COLAB:
        print("\nğŸ“Š æœ¬åœ°ç¯å¢ƒä¿¡æ¯:")
        print(f"   æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
        print(f"   Pythonç‰ˆæœ¬: {platform.python_version()}")
        print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   GPU: {torch.cuda.get_device_name(0)}")

    # é‡è¦æç¤º
    print("\nâš ï¸  å­˜å‚¨è¯´æ˜ï¼š")
    if IS_COLAB:
        print("   â€¢ æ‰€æœ‰æ¨¡å‹éƒ½åªä¿å­˜åœ¨Google Drive")
    else:
        print(f"   â€¢ æ‰€æœ‰æ¨¡å‹ä¿å­˜åœ¨: {TrainingConfig.BASE_DIR}")
    print("   â€¢ å·²ç¦ç”¨æ‰€æœ‰å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™ç´§æ€¥å­˜æ¡£")
    print("   â€¢ ç´§æ€¥å­˜æ¡£æ¯5åˆ†é’Ÿè‡ªåŠ¨ä¿å­˜ä¸€æ¬¡")
    print("   â€¢ è®­ç»ƒå®Œæˆåï¼Œåªä¿ç•™æœ€ç»ˆæ¨¡å‹")
    print("=" * 80)

    # åˆ›å»ºç›®å½•ç»“æ„
    config = TrainingConfig
    config.create_directories()

    # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
    logger = setup_logging(config.LOG_FILE)
    logger.info("è®­ç»ƒè„šæœ¬å¼€å§‹æ‰§è¡Œ - åªä¿ç•™ç´§æ€¥å­˜æ¡£")
    logger.info(f"å·¥ä½œç›®å½•: {config.BASE_DIR}")
    logger.info("å·²ç¦ç”¨å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™ç´§æ€¥å­˜æ¡£")

    # åˆå§‹åŒ–åˆ†è¯å™¨
    logger.info("åˆå§‹åŒ–åˆ†è¯å™¨...")
    try:
        tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
        tokenizer.pad_token = tokenizer.eos_token
        logger.info("âœ“ åˆ†è¯å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"åˆ†è¯å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        print(f"âŒ åˆ†è¯å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return

    # è®­ç»ƒæ‰€æœ‰æ•°æ®é›†
    all_metrics = {}

    for dataset_config in config.DATASETS:
        dataset_name = dataset_config['name']

        print(f"\n{'=' * 60}")
        print(f"è®­ç»ƒæ•°æ®é›†: {dataset_name}")
        print(f"å­˜å‚¨ä½ç½®: {'Google Drive' if IS_COLAB else 'æœ¬åœ°ç¡¬ç›˜'}")
        print(f"å­˜æ¡£ç­–ç•¥: åªä¿ç•™ç´§æ€¥å­˜æ¡£")
        print(f"{'=' * 60}")

        # å¼€å§‹è®­ç»ƒè®¡æ—¶
        start_time = time.time()

        # è®­ç»ƒæ¨¡å‹
        perplexities, train_result = train_with_emergency_only(
            config, dataset_config, dataset_name, tokenizer, logger
            )

        # è®¡ç®—è®­ç»ƒæ—¶é—´
        training_time = time.time() - start_time

        if perplexities is not None:
            # ä¿å­˜è®­ç»ƒç»“æœ
            metrics = {
                "perplexities": perplexities,
                "final_perplexity": perplexities[-1] if perplexities else None,
                "min_perplexity": min(perplexities) if perplexities else None,
                "training_time": training_time,
                "total_steps": len(perplexities),
                "dataset": dataset_name,
                "file_path": dataset_config['file_path'],
                "model_dir": dataset_config['model_dir'],
                "completed_at": datetime.now().isoformat()
                }

            all_metrics[dataset_name] = metrics

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            result_file = os.path.join(
                dataset_config['model_dir'],
                "perplexity_results.json")
            with open(result_file, 'w') as f:
                json.dump(metrics, f, indent=2)

            logger.info(f"å›°æƒ‘åº¦ç»“æœä¿å­˜åˆ°: {result_file}")

            # æ‰“å°è®­ç»ƒç»Ÿè®¡
            print(f"\nâœ… è®­ç»ƒå®Œæˆ - {dataset_name}:")
            print(
                f"   æœ€ç»ˆå›°æƒ‘åº¦: {perplexities[-1]:.4f}" if perplexities else "   æœ€ç»ˆå›°æƒ‘åº¦: N/A")
            print(
                f"   æœ€å°å›°æƒ‘åº¦: {min(perplexities):.4f}" if perplexities else "   æœ€å°å›°æƒ‘åº¦: N/A")
            print(f"   è®­ç»ƒæ­¥æ•°: {len(perplexities)}")
            print(f"   è®­ç»ƒæ—¶é—´: {training_time / 60:.2f} åˆ†é’Ÿ")

        else:
            logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {dataset_name}")
            all_metrics[dataset_name] = None

    # æ‰“å°æœ€ç»ˆæ±‡æ€»
    print(f"\n{'=' * 80}")
    print("è®­ç»ƒå®Œæˆæ±‡æ€»")
    print(f"{'=' * 80}")

    for dataset_name, metrics in all_metrics.items():
        if metrics:
            final_ppl = metrics['final_perplexity']
            min_ppl = metrics['min_perplexity']
            steps = metrics['total_steps']
            time_min = metrics['training_time'] / 60

            print(f"âœ… {dataset_name}:")
            print(f"   æœ€ç»ˆå›°æƒ‘åº¦: {final_ppl:.4f}")
            print(f"   æœ€å°å›°æƒ‘åº¦: {min_ppl:.4f}")
            print(f"   è®­ç»ƒæ­¥æ•°: {steps}")
            print(f"   è®­ç»ƒæ—¶é—´: {time_min:.1f}åˆ†é’Ÿ")
            print(f"   å­˜å‚¨ä½ç½®: {metrics['model_dir']}")
        else:
            print(f"âŒ {dataset_name}: è®­ç»ƒå¤±è´¥")

    print(f"{'=' * 80}")

    # ç¯å¢ƒç‰¹å®šæç¤º
    if IS_COLAB:
        print("\nğŸ“Š è®­ç»ƒçŠ¶æ€æ±‡æ€»:")
        print(f"   æ—¥å¿—æ–‡ä»¶: {config.LOG_FILE}")
        print(f"   æ‰€æœ‰æ¨¡å‹ä¿å­˜åœ¨: {config.RESULTS_DIR}")

        print("\nğŸ“ æ¨¡å‹ç›®å½•ç»“æ„:")
        print(f"   {config.RESULTS_DIR}/")
        for dataset in config.DATASETS:
            print(f"   â”œâ”€â”€ {os.path.basename(dataset['model_dir'])}")
            print(f"   â”‚   â””â”€â”€ final_model/ (æœ€ç»ˆæ¨¡å‹)")
    else:
        print("\nğŸ“Š è®­ç»ƒçŠ¶æ€æ±‡æ€»:")
        print(f"   æ—¥å¿—æ–‡ä»¶: {config.LOG_FILE}")
        print(f"   æ‰€æœ‰æ¨¡å‹ä¿å­˜åœ¨: {config.RESULTS_DIR}")
        print(f"   æ•°æ®ç›®å½•: {config.DATA_DIR}")

        print("\nğŸ“ æœ¬åœ°ç›®å½•ç»“æ„:")
        print(f"   {config.BASE_DIR}/")
        print(f"   â”œâ”€â”€ data/ (æ•°æ®æ–‡ä»¶)")
        print(f"   â”œâ”€â”€ results/ (è®­ç»ƒç»“æœ)")
        print(f"   â”‚   â”œâ”€â”€ model_natural/")
        print(f"   â”‚   â”œâ”€â”€ model_reversed/")
        print(f"   â”‚   â””â”€â”€ model_parity_negation/")
        print(f"   â”œâ”€â”€ emergency_backups/ (ç´§æ€¥å­˜æ¡£)")
        print(f"   â””â”€â”€ training.log (æ—¥å¿—æ–‡ä»¶)")

    print("\nâš ï¸  å­˜æ¡£ç­–ç•¥è¯´æ˜:")
    print("   å·²ç¦ç”¨æ‰€æœ‰å¸¸è§„æ£€æŸ¥ç‚¹")
    print("   åªä¿ç•™ç´§æ€¥å­˜æ¡£ï¼ˆæ¯5åˆ†é’Ÿè‡ªåŠ¨ä¿å­˜ï¼‰")
    print("   è®­ç»ƒå®Œæˆåï¼Œåªä¿ç•™æœ€ç»ˆæ¨¡å‹ï¼Œæ¸…ç†ç´§æ€¥å­˜æ¡£")

    logger.info(f"è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆäº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nğŸ è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆäº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


# ========== è„šæœ¬å…¥å£ ==========
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

        # ä¿å­˜é”™è¯¯ä¿¡æ¯
        try:
            error_file = os.path.join(TrainingConfig.BASE_DIR, "error_log.txt")
            with open(error_file, 'a') as f:  # è¿½åŠ æ¨¡å¼
                f.write(f"\n{'=' * 60}\n")
                f.write(f"é”™è¯¯æ—¶é—´: {datetime.now().isoformat()}\n")
                f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n\n")
                f.write(traceback.format_exc())

            print(f"ğŸ“ é”™è¯¯æ—¥å¿—å·²è¿½åŠ åˆ°: {error_file}")
        except BaseException:
            pass
